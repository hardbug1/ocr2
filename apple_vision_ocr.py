#!/usr/bin/env python3
"""
Apple Vision APIë¥¼ ì‚¬ìš©í•œ í•œê¸€ OCR ì‹œìŠ¤í…œ
macOSì—ì„œ Appleì˜ Vision frameworkë¥¼ PyObjCë¡œ ì ‘ê·¼í•˜ì—¬ í•œê¸€ ì¸ì‹ ìˆ˜í–‰

ì„¤ì¹˜ ë°©ë²•:
pip install pyobjc-framework-Vision pyobjc-framework-Quartz wurlitzer

ì‚¬ìš©ë²•:
python apple_vision_ocr.py image_path.jpg
"""

import sys
import pathlib
import time
from typing import List, Dict, Any, Optional

import Quartz
import Vision
from Cocoa import NSURL
from Foundation import NSDictionary
from wurlitzer import pipes

class AppleVisionOCR:
    """Apple Vision APIë¥¼ ì‚¬ìš©í•œ í•œê¸€ OCR í´ë˜ìŠ¤"""
    
    def __init__(self, recognition_level: str = "accurate"):
        """
        Apple Vision OCR ì´ˆê¸°í™”
        
        Args:
            recognition_level: ì¸ì‹ ì •í™•ë„ ë ˆë²¨ ("fast" ë˜ëŠ” "accurate")
        """
        self.recognition_level = recognition_level
        print("ğŸ Apple Vision OCR ì´ˆê¸°í™” ì¤‘...")
        
        # ì§€ì›ë˜ëŠ” ì–¸ì–´ í™•ì¸
        self.supported_languages = self._get_supported_languages()
        print(f"ğŸ“‹ ì§€ì› ì–¸ì–´: {len(self.supported_languages)}ê°œ")
        
        # í•œê¸€ ì§€ì› í™•ì¸
        if any(lang in self.supported_languages for lang in ['ko', 'ko-KR', 'kor']):
            print("âœ… í•œê¸€ ì§€ì› í™•ì¸ë¨")
        else:
            print("âš ï¸  í•œê¸€ ì§€ì› ìƒíƒœ ë¶ˆí™•ì‹¤")
    
    def _get_supported_languages(self) -> List[str]:
        """ì§€ì›ë˜ëŠ” ì–¸ì–´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # Vision frameworkì—ì„œ ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            request = Vision.VNRecognizeTextRequest.alloc().init()
            
            # macOS ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¸ ë©”ì„œë“œ ì‚¬ìš©
            try:
                languages = request.supportedRecognitionLanguagesAndReturnError_(None)[0]
                if languages:
                    return list(languages)
            except:
                # êµ¬ë²„ì „ macOSì—ì„œëŠ” ê¸°ë³¸ ì–¸ì–´ ëª©ë¡ ì‚¬ìš©
                pass
            
            # ê¸°ë³¸ ì–¸ì–´ ëª©ë¡ (ì¼ë°˜ì ìœ¼ë¡œ ì§€ì›ë˜ëŠ” ì–¸ì–´ë“¤)
            return ['en-US', 'ko-KR', 'ja-JP', 'zh-CN', 'zh-TW', 'fr-FR', 'de-DE', 'es-ES', 'it-IT', 'pt-BR', 'ru-RU']
        except Exception as e:
            print(f"âš ï¸  ì–¸ì–´ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return ['en-US', 'ko-KR']
    
    def process_image(self, image_path: str) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            image_path: ì²˜ë¦¬í•  ì´ë¯¸ì§€ ê²½ë¡œ
            
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì •ë³´
        """
        start_time = time.time()
        
        # ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸
        if not pathlib.Path(image_path).exists():
            raise FileNotFoundError(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        print(f"ğŸ” ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘: {image_path}")
        
        # ì´ë¯¸ì§€ URL ìƒì„±
        input_url = NSURL.fileURLWithPath_(str(pathlib.Path(image_path).resolve()))
        
        # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
        results = []
        
        try:
            with pipes() as (out, err):
                # Vision frameworkê°€ ì‹œìŠ¤í…œ ë¡œê·¸ë¥¼ ì¶œë ¥í•˜ë¯€ë¡œ ì–µì œ
                input_image = Quartz.CIImage.imageWithContentsOfURL_(input_url)
                
                if not input_image:
                    raise ValueError("ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
                # Vision ìš”ì²­ í•¸ë“¤ëŸ¬ ìƒì„±
                vision_handler = Vision.VNImageRequestHandler.alloc().initWithCIImage_options_(
                    input_image, None
                )
                
                # Vision ìš”ì²­ ìƒì„± (ë™ê¸° ë°©ì‹)
                vision_request = Vision.VNRecognizeTextRequest.alloc().init()
                
                # ì¸ì‹ ë ˆë²¨ ì„¤ì •
                if self.recognition_level == "accurate":
                    vision_request.setRecognitionLevel_(Vision.VNRequestTextRecognitionLevelAccurate)
                else:
                    vision_request.setRecognitionLevel_(Vision.VNRequestTextRecognitionLevelFast)
                
                # í•œê¸€ ì–¸ì–´ ì„¤ì •
                try:
                    # í•œê¸€ê³¼ ì˜ì–´ ëª¨ë‘ ì§€ì›í•˜ë„ë¡ ì„¤ì •
                    languages = []
                    if 'ko-KR' in self.supported_languages:
                        languages.append('ko-KR')
                    elif 'ko' in self.supported_languages:
                        languages.append('ko')
                    
                    if 'en-US' in self.supported_languages:
                        languages.append('en-US')
                    elif 'en' in self.supported_languages:
                        languages.append('en')
                    
                    if languages:
                        vision_request.setRecognitionLanguages_(languages)
                except Exception as e:
                    print(f"âš ï¸  ì–¸ì–´ ì„¤ì • ì˜¤ë¥˜: {e}")
                
                # ìš”ì²­ ì‹¤í–‰
                success = vision_handler.performRequests_error_([vision_request], None)
                
                if not success:
                    raise RuntimeError("Vision ìš”ì²­ ì‹¤í–‰ ì‹¤íŒ¨")
                
                # ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                observations = vision_request.results()
                
                for observation in observations:
                    try:
                        # ìµœê³  ì‹ ë¢°ë„ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                        recognized_text = observation.topCandidates_(1)[0]
                        text = recognized_text.string()
                        confidence = recognized_text.confidence()
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        bounding_box = observation.boundingBox()
                        
                        results.append({
                            'text': text,
                            'confidence': confidence,
                            'bounding_box': {
                                'x': bounding_box.origin.x,
                                'y': bounding_box.origin.y,
                                'width': bounding_box.size.width,
                                'height': bounding_box.size.height
                            }
                        })
                    except Exception as e:
                        print(f"âš ï¸  í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                'success': False,
                'error': str(e),
                'processing_time': time.time() - start_time
            }
        
        # ê²°ê³¼ ì •ë¦¬
        processing_time = time.time() - start_time
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì •ë¦¬
        extracted_texts = []
        total_confidence = 0
        
        for result in results:
            text = result['text'].strip()
            if text:  # ë¹ˆ í…ìŠ¤íŠ¸ ì œì™¸
                extracted_texts.append(text)
                total_confidence += result['confidence']
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
        full_text = '\n'.join(extracted_texts)
        
        # í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
        avg_confidence = total_confidence / len(results) if results else 0
        
        result = {
            'success': True,
            'full_text': full_text,
            'extracted_texts': extracted_texts,
            'detailed_results': results,
            'total_texts': len(extracted_texts),
            'avg_confidence': avg_confidence,
            'processing_time': processing_time,
            'recognition_level': self.recognition_level,
            'supported_languages': self.supported_languages
        }
        
        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {len(extracted_texts)}ê°œ í…ìŠ¤íŠ¸, í‰ê·  ì‹ ë¢°ë„ {avg_confidence:.1%}, {processing_time:.2f}ì´ˆ")
        
        return result
    
    def process_multiple_images(self, image_paths: List[str]) -> List[Dict[str, Any]]:
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ ì¼ê´„ ì²˜ë¦¬
        
        Args:
            image_paths: ì²˜ë¦¬í•  ì´ë¯¸ì§€ ê²½ë¡œ ëª©ë¡
            
        Returns:
            ê° ì´ë¯¸ì§€ë³„ ì²˜ë¦¬ ê²°ê³¼
        """
        results = []
        
        print(f"ğŸ“ {len(image_paths)}ê°œ ì´ë¯¸ì§€ ì¼ê´„ ì²˜ë¦¬ ì‹œì‘")
        
        for i, image_path in enumerate(image_paths, 1):
            print(f"\n[{i}/{len(image_paths)}] ì²˜ë¦¬ ì¤‘...")
            result = self.process_image(image_path)
            result['image_path'] = image_path
            results.append(result)
        
        print(f"\nğŸ‰ ì¼ê´„ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ì´ë¯¸ì§€")
        
        return results
    
    def compare_recognition_levels(self, image_path: str) -> Dict[str, Any]:
        """
        ë¹ ë¥¸ ì¸ì‹ê³¼ ì •í™•í•œ ì¸ì‹ ì„±ëŠ¥ ë¹„êµ
        
        Args:
            image_path: ë¹„êµí•  ì´ë¯¸ì§€ ê²½ë¡œ
            
        Returns:
            ë‘ ë°©ë²•ì˜ ë¹„êµ ê²°ê³¼
        """
        print("ğŸ”¬ ì¸ì‹ ë ˆë²¨ ë¹„êµ ì‹œì‘...")
        
        # ë¹ ë¥¸ ì¸ì‹
        print("\nğŸ“± ë¹ ë¥¸ ì¸ì‹ ëª¨ë“œ í…ŒìŠ¤íŠ¸...")
        fast_ocr = AppleVisionOCR(recognition_level="fast")
        fast_result = fast_ocr.process_image(image_path)
        
        # ì •í™•í•œ ì¸ì‹
        print("\nğŸ¯ ì •í™•í•œ ì¸ì‹ ëª¨ë“œ í…ŒìŠ¤íŠ¸...")
        accurate_ocr = AppleVisionOCR(recognition_level="accurate")
        accurate_result = accurate_ocr.process_image(image_path)
        
        # ë¹„êµ ê²°ê³¼
        comparison = {
            'fast_recognition': {
                'texts_count': fast_result.get('total_texts', 0),
                'confidence': fast_result.get('avg_confidence', 0),
                'processing_time': fast_result.get('processing_time', 0),
                'full_text': fast_result.get('full_text', '')
            },
            'accurate_recognition': {
                'texts_count': accurate_result.get('total_texts', 0),
                'confidence': accurate_result.get('avg_confidence', 0),
                'processing_time': accurate_result.get('processing_time', 0),
                'full_text': accurate_result.get('full_text', '')
            }
        }
        
        # ì„±ëŠ¥ ë¶„ì„
        fast_time = fast_result.get('processing_time', 0.1)
        accurate_time = accurate_result.get('processing_time', 0.1)
        speed_improvement = (accurate_time - fast_time) / fast_time * 100
        
        fast_conf = fast_result.get('avg_confidence', 0)
        accurate_conf = accurate_result.get('avg_confidence', 0)
        confidence_difference = (accurate_conf - fast_conf) * 100
        
        comparison['analysis'] = {
            'speed_improvement_fast': f"{-speed_improvement:.1f}%" if speed_improvement > 0 else f"{abs(speed_improvement):.1f}%",
            'confidence_improvement_accurate': f"{confidence_difference:.1f}%",
            'recommendation': "accurate" if confidence_difference > 5 else "fast"
        }
        
        print(f"ğŸ“Š ë¹„êµ ì™„ë£Œ:")
        print(f"   ë¹ ë¥¸ ì¸ì‹: {fast_result.get('total_texts', 0)}ê°œ í…ìŠ¤íŠ¸, {fast_result.get('avg_confidence', 0):.1%} ì‹ ë¢°ë„, {fast_result.get('processing_time', 0):.2f}ì´ˆ")
        print(f"   ì •í™•í•œ ì¸ì‹: {accurate_result.get('total_texts', 0)}ê°œ í…ìŠ¤íŠ¸, {accurate_result.get('avg_confidence', 0):.1%} ì‹ ë¢°ë„, {accurate_result.get('processing_time', 0):.2f}ì´ˆ")
        print(f"   ê¶Œì¥ ë°©ë²•: {comparison['analysis']['recommendation']}")
        
        return comparison

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python apple_vision_ocr.py <ì´ë¯¸ì§€_ê²½ë¡œ> [ì˜µì…˜]")
        print("ì˜µì…˜:")
        print("  --fast     : ë¹ ë¥¸ ì¸ì‹ ëª¨ë“œ")
        print("  --accurate : ì •í™•í•œ ì¸ì‹ ëª¨ë“œ (ê¸°ë³¸ê°’)")
        print("  --compare  : ë‘ ë°©ë²• ë¹„êµ")
        print("ì˜ˆì‹œ:")
        print("  python apple_vision_ocr.py korean_document.jpg")
        print("  python apple_vision_ocr.py korean_document.jpg --fast")
        print("  python apple_vision_ocr.py korean_document.jpg --compare")
        return
    
    image_path = sys.argv[1]
    
    # ì˜µì…˜ ì²˜ë¦¬
    if '--compare' in sys.argv:
        # ë¹„êµ ëª¨ë“œ
        ocr = AppleVisionOCR()
        comparison = ocr.compare_recognition_levels(image_path)
        
        print("\n" + "="*50)
        print("ğŸ”¬ Apple Vision OCR ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
        print("="*50)
        
        for mode, result in comparison.items():
            if mode != 'analysis':
                print(f"\nğŸ“‹ {mode.replace('_', ' ').title()}:")
                print(f"   í…ìŠ¤íŠ¸ ìˆ˜: {result['texts_count']}ê°œ")
                print(f"   í‰ê·  ì‹ ë¢°ë„: {result['confidence']:.1%}")
                print(f"   ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
                print(f"   ì¶”ì¶œ í…ìŠ¤íŠ¸:")
                print(f"   {result['full_text'][:200]}...")
        
        print(f"\nğŸ¯ ë¶„ì„ ê²°ê³¼:")
        print(f"   ê¶Œì¥ ë°©ë²•: {comparison['analysis']['recommendation']}")
        
    else:
        # ì¼ë°˜ ëª¨ë“œ
        recognition_level = "fast" if '--fast' in sys.argv else "accurate"
        
        ocr = AppleVisionOCR(recognition_level=recognition_level)
        result = ocr.process_image(image_path)
        
        if result['success']:
            print("\n" + "="*50)
            print("ğŸ Apple Vision OCR ê²°ê³¼")
            print("="*50)
            print(f"ğŸ“Š í†µê³„:")
            print(f"   ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {result['total_texts']}ê°œ")
            print(f"   í‰ê·  ì‹ ë¢°ë„: {result['avg_confidence']:.1%}")
            print(f"   ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
            print(f"   ì¸ì‹ ë ˆë²¨: {result['recognition_level']}")
            print(f"   ì§€ì› ì–¸ì–´: {', '.join(result['supported_languages'][:5])}...")
            
            print(f"\nğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸:")
            print("-" * 30)
            print(result['full_text'])
            
            if len(result['detailed_results']) > 1:
                print(f"\nğŸ” ìƒì„¸ ê²°ê³¼:")
                for i, detail in enumerate(result['detailed_results'], 1):
                    print(f"   {i}. \"{detail['text']}\" (ì‹ ë¢°ë„: {detail['confidence']:.1%})")
        else:
            print(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {result['error']}")

if __name__ == "__main__":
    main() 