#!/usr/bin/env python3
"""
ê°œì„ ëœ í•œê¸€ OCR íŒŒì´í”„ë¼ì¸
ë” ë‚˜ì€ í•œê¸€ ì¸ì‹ì„ ìœ„í•œ ìµœì í™”ëœ ë°©ë²•ë“¤
"""

import cv2
import numpy as np
from PIL import Image, ImageEnhance
import easyocr
import json
import time
import argparse
from typing import Dict, List, Tuple, Optional
import os
from mps_warning_fix import suppress_mps_warnings, mps_safe_environment

# MPS ê²½ê³  ì–µì œ
suppress_mps_warnings()

class ImprovedKoreanOCR:
    """ê°œì„ ëœ í•œê¸€ OCR í´ë˜ìŠ¤"""
    
    def __init__(self, use_gpu: bool = True):
        self.use_gpu = use_gpu
        self.reader = None
        self.initialize_ocr()
    
    def initialize_ocr(self):
        """OCR ì—”ì§„ ì´ˆê¸°í™”"""
        try:
            print("ğŸ”§ EasyOCR ì´ˆê¸°í™” ì¤‘...")
            self.reader = easyocr.Reader(['ko', 'en'], gpu=self.use_gpu)
            print("âœ… EasyOCR ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ EasyOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    def enhanced_korean_preprocessing(self, image_path: str) -> np.ndarray:
        """í•œê¸€ íŠ¹í™” ê³ ê¸‰ ì „ì²˜ë¦¬"""
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        
        print("ğŸ”§ ê³ ê¸‰ í•œê¸€ ì „ì²˜ë¦¬ ì‹œì‘...")
        
        # 1. ì´ë¯¸ì§€ í¬ê¸° ìµœì í™” (í•œê¸€ ì¸ì‹ì— ìµœì )
        height, width = image.shape[:2]
        if width > 2000 or height > 2000:
            scale = min(2000/width, 2000/height)
            new_width = int(width * scale)
            new_height = int(height * scale)
            image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
            print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {width}x{height} â†’ {new_width}x{new_height}")
        
        # 2. ìƒ‰ìƒ ê³µê°„ ë³€í™˜ ë° ëŒ€ë¹„ í–¥ìƒ
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        
        # CLAHE ì ìš© (í•œê¸€ íš ê°•ì¡°)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        l = clahe.apply(l)
        
        enhanced = cv2.merge([l, a, b])
        image = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
        
        # 3. ë…¸ì´ì¦ˆ ì œê±° (í•œê¸€ íš ë³´ì¡´)
        image = cv2.bilateralFilter(image, 9, 75, 75)
        
        # 4. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # 5. ì ì‘í˜• ì„ê³„ê°’ (í•œê¸€ íŠ¹ì„± ê³ ë ¤)
        # Gaussian ë°©ë²•ì´ í•œê¸€ì— ë” íš¨ê³¼ì 
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 11, 2
        )
        
        # 6. ëª¨í´ë¡œì§€ ì—°ì‚° (í•œê¸€ íš ì—°ê²°)
        kernel = np.ones((2,2), np.uint8)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        
        # 7. ìƒ¤í”„ë‹ (í•œê¸€ íš ì„ ëª…í™”)
        kernel_sharpen = np.array([
            [-1, -1, -1],
            [-1,  9, -1],
            [-1, -1, -1]
        ])
        sharpened = cv2.filter2D(binary, -1, kernel_sharpen)
        
        print("âœ… ê³ ê¸‰ í•œê¸€ ì „ì²˜ë¦¬ ì™„ë£Œ")
        return sharpened
    
    def multi_scale_recognition(self, image: np.ndarray) -> List[Dict]:
        """ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì¸ì‹"""
        
        results = []
        scales = [1.0, 1.2, 0.8]  # ë‹¤ì–‘í•œ í¬ê¸°ë¡œ í…ŒìŠ¤íŠ¸
        
        for scale in scales:
            if scale != 1.0:
                height, width = image.shape[:2]
                new_width = int(width * scale)
                new_height = int(height * scale)
                scaled_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
            else:
                scaled_image = image
            
            # OCR ì‹¤í–‰ (MPS ì•ˆì „ í™˜ê²½ì—ì„œ)
            try:
                with mps_safe_environment():
                    ocr_results = self.reader.readtext(scaled_image, detail=1)
                
                for bbox, text, confidence in ocr_results:
                    # ìŠ¤ì¼€ì¼ ë³´ì •
                    if scale != 1.0:
                        bbox = [[int(x/scale), int(y/scale)] for x, y in bbox]
                    
                    results.append({
                        'text': text,
                        'confidence': confidence,
                        'bbox': bbox,
                        'scale': scale
                    })
            except Exception as e:
                print(f"âš ï¸ ìŠ¤ì¼€ì¼ {scale} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        return results
    
    def post_process_korean_text(self, text: str) -> str:
        """í•œê¸€ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬"""
        
        # ìì£¼ ë°œìƒí•˜ëŠ” OCR ì˜¤ë¥˜ ìˆ˜ì •
        corrections = {
            # ììŒ/ëª¨ìŒ ì˜¤ì¸ì‹ ìˆ˜ì •
            'ã…‡': 'o',  # ì˜ì–´ oì™€ í•œê¸€ ã…‡ êµ¬ë¶„
            'ã…': 'm',  # ì˜ì–´ mê³¼ í•œê¸€ ã… êµ¬ë¶„
            '|': 'l',   # ì„¸ë¡œì„ ì„ lë¡œ ìˆ˜ì •
            '0': 'O',   # ìˆ«ì 0ê³¼ ì˜ì–´ O êµ¬ë¶„
            '1': 'l',   # ìˆ«ì 1ê³¼ ì˜ì–´ l êµ¬ë¶„
            
            # í•œê¸€ íŠ¹ìˆ˜ íŒ¨í„´ ìˆ˜ì •
            'ã…œ ã…': 'ì™€',
            'ã…“ ã…£': 'ì–´',
            'ã…¡ ã…£': 'ì˜',
            
            # ì¼ë°˜ì ì¸ ì˜¤íƒ€ ìˆ˜ì •
            'ì„œë¬¼ì‹œ': 'ì„œìš¸ì‹œ',
            'í…Œí•´ë€ë¡œ': 'í…Œí—¤ë€ë¡œ',
            'ì¶•ì •': 'ì¸¡ì •',
            'ìœ„ëŠ”': 'ìˆëŠ”',
            'ì»´í“¨í„°;': 'ì»´í“¨í„°,',
        }
        
        corrected_text = text
        for wrong, correct in corrections.items():
            corrected_text = corrected_text.replace(wrong, correct)
        
        return corrected_text
    
    def process_image(self, image_path: str, output_path: Optional[str] = None) -> Dict:
        """ì´ë¯¸ì§€ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜"""
        
        start_time = time.time()
        
        try:
            # 1. ê³ ê¸‰ ì „ì²˜ë¦¬
            processed_image = self.enhanced_korean_preprocessing(image_path)
            
            # 2. ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì¸ì‹
            print("ğŸ” ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ OCR ì‹¤í–‰ ì¤‘...")
            all_results = self.multi_scale_recognition(processed_image)
            
            # 3. ê²°ê³¼ í†µí•© ë° ì¤‘ë³µ ì œê±°
            final_results = self.merge_results(all_results)
            
            # 4. í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬
            combined_text = ' '.join([r['text'] for r in final_results])
            corrected_text = self.post_process_korean_text(combined_text)
            
            processing_time = time.time() - start_time
            
            result = {
                'image_path': image_path,
                'text': corrected_text,
                'processing_time': processing_time,
                'method': 'Improved Korean OCR',
                'total_detections': len(final_results),
                'detailed_results': final_results,
                'improvements': [
                    'Enhanced Korean preprocessing',
                    'Multi-scale recognition',
                    'Korean-specific post-processing',
                    'Adaptive thresholding',
                    'Morphological operations'
                ]
            }
            
            # ê²°ê³¼ ì¶œë ¥
            print("\n" + "="*60)
            print("ğŸ“Š ê°œì„ ëœ í•œê¸€ OCR ê²°ê³¼")
            print("="*60)
            print(f"ğŸ¯ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {corrected_text}")
            print(f"â±ï¸  ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
            print(f"ğŸ” ê²€ì¶œëœ ì˜ì—­: {len(final_results)}ê°œ")
            print(f"ğŸš€ ì ìš©ëœ ê°œì„ ì‚¬í•­: {len(result['improvements'])}ê°œ")
            print("="*60)
            
            # ê²°ê³¼ ì €ì¥
            if output_path:
                os.makedirs(os.path.dirname(output_path), exist_ok=True)
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ë¨: {output_path}")
            
            return result
            
        except Exception as e:
            print(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def merge_results(self, results: List[Dict]) -> List[Dict]:
        """ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê²°ê³¼ í†µí•©"""
        
        if not results:
            return []
        
        # ì‹ ë¢°ë„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        results.sort(key=lambda x: x['confidence'], reverse=True)
        
        # ì¤‘ë³µ ì œê±° (IoU ê¸°ë°˜)
        merged = []
        for result in results:
            is_duplicate = False
            
            for existing in merged:
                if self.calculate_iou(result['bbox'], existing['bbox']) > 0.5:
                    # ë” ë†’ì€ ì‹ ë¢°ë„ ì„ íƒ
                    if result['confidence'] > existing['confidence']:
                        merged.remove(existing)
                        merged.append(result)
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                merged.append(result)
        
        return merged
    
    def calculate_iou(self, bbox1: List, bbox2: List) -> float:
        """IoU ê³„ì‚°"""
        try:
            # ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì§ì‚¬ê°í˜•ìœ¼ë¡œ ë³€í™˜
            def bbox_to_rect(bbox):
                xs = [point[0] for point in bbox]
                ys = [point[1] for point in bbox]
                return min(xs), min(ys), max(xs), max(ys)
            
            x1_min, y1_min, x1_max, y1_max = bbox_to_rect(bbox1)
            x2_min, y2_min, x2_max, y2_max = bbox_to_rect(bbox2)
            
            # êµì§‘í•© ê³„ì‚°
            inter_x_min = max(x1_min, x2_min)
            inter_y_min = max(y1_min, y2_min)
            inter_x_max = min(x1_max, x2_max)
            inter_y_max = min(y1_max, y2_max)
            
            if inter_x_max <= inter_x_min or inter_y_max <= inter_y_min:
                return 0.0
            
            inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)
            
            # í•©ì§‘í•© ê³„ì‚°
            area1 = (x1_max - x1_min) * (y1_max - y1_min)
            area2 = (x2_max - x2_min) * (y2_max - y2_min)
            union_area = area1 + area2 - inter_area
            
            return inter_area / union_area if union_area > 0 else 0.0
            
        except Exception:
            return 0.0

def main():
    parser = argparse.ArgumentParser(description='ê°œì„ ëœ í•œê¸€ OCR')
    parser.add_argument('input', help='ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ')
    parser.add_argument('-o', '--output', help='ì¶œë ¥ JSON íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--cpu', action='store_true', help='CPU ëª¨ë“œ ì‚¬ìš©')
    
    args = parser.parse_args()
    
    # OCR ì‹¤í–‰
    ocr = ImprovedKoreanOCR(use_gpu=not args.cpu)
    result = ocr.process_image(args.input, args.output)
    
    if result:
        print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“ˆ ì„±ëŠ¥ ê°œì„ ì‚¬í•­:")
        for improvement in result['improvements']:
            print(f"   âœ… {improvement}")
    else:
        print("âŒ ì²˜ë¦¬ ì‹¤íŒ¨")

if __name__ == "__main__":
    main() 